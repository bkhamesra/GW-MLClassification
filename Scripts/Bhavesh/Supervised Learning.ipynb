{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "import time, glob, os, math\n",
    "from matplotlib import cm \n",
    "\n",
    "from sklearn.decomposition import PCA, FastICA, KernelPCA, FactorAnalysis\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.mixture import GaussianMixture as GM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_data(metafile, data):\n",
    "        assert(os.path.exists(metafile)),\"Path to metadata file does not exist\"\n",
    "        datafile = file(metafile)\n",
    "        datafile.seek(0)\n",
    "        for line in datafile:\n",
    "                if data in line:\n",
    "                        break\n",
    "        line = line.split(',')\n",
    "        data_value = line[-1].rstrip()\n",
    "        datafile.close()\n",
    "        return data_value\n",
    "\n",
    "def plot(x, y, xlabel, ylabel):     #Create a plot\n",
    "    plt.figure()\n",
    "    plt.plot(x,y,color='b')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def scatter(ax, x, y, clr, xlabel, ylabel, title):     #Create a scatter plot\n",
    "\n",
    "    clr_label = {0:'orange', 1:'forestgreen', 2:'deepskyblue',3:'gold', 4:'b', 5:'k', 6:'red', 7:'darkmagenta' }\n",
    "    names = {'NonSpinning':0,'AlignedSpins':1,'Precessing':2}\n",
    "    target_names = np.vectorize(names.get)(clr)\n",
    "    target_labels =  np.vectorize(clr_label.get)(target_names)\n",
    "   \n",
    "    ax.scatter(x,y,facecolors=target_labels, edgecolors=None) \n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Principal Component Analysis\n",
    "def func_PCA(n_comp, data):\n",
    "    data_copy = np.copy(data)\n",
    "    num_samples, num_features = np.shape(data_copy)\n",
    "    time_init = time.time()\n",
    "    clf = PCA(svd_solver='full', n_components=n_comp, random_state=rs)   \n",
    "    transformed_data = clf.fit_transform(data_copy)\n",
    "    var = clf.explained_variance_\n",
    "    score = clf.score(data_copy)\n",
    "    time_pca = time.time() - time_init\n",
    "    \n",
    "    #print(\"Projected {} samples from {} to {} with score {}\" .format(num_samples, num_features, n_comp, score))\n",
    "    return transformed_data, time_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading the Dataset\n",
    "\n",
    "data, wf_tag, metadata = [], [],[]\n",
    "GT_filepaths = sorted(glob.glob(\"FilteredData/GT*.txt\"))\n",
    "SXS_filepaths = sorted(glob.glob(\"FilteredData/SXS*.txt\"))\n",
    "\n",
    "for f in GT_filepaths:\n",
    "    dataset = np.loadtxt(f)\n",
    "    \n",
    "    dataset = np.concatenate(dataset.T)\n",
    "    data.append(dataset)\n",
    "    wf_tag.append(os.path.basename(f).split(\".\")[0])\n",
    "    \n",
    "    metafile = os.path.join(\"Metadata\", \"Metadata_\"+wf_tag[-1]+\".csv\")\n",
    "    metadata.append(output_data(metafile, 'spin-type'))\n",
    "    \n",
    "    \n",
    "for f in SXS_filepaths:\n",
    "    dataset = np.loadtxt(f)\n",
    "    dataset = np.concatenate(dataset)\n",
    "    data.append(dataset)\n",
    "    wf_tag.append(os.path.basename(f).split(\".\")[0])\n",
    "    \n",
    "    metafile = os.path.join(\"Metadata\", \"Metadata_\"+wf_tag[-1]+\".csv\")\n",
    "    metadata.append(output_data(metafile, 'spin-type'))\n",
    "    \n",
    "data = np.matrix(data)\n",
    "y = np.array(metadata)\n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_dectree(data, trainsize, pca_comp):\n",
    "    data_train, data_test, y_train, y_test = train_test_split(data, y, train_size=trainsize, random_state=12)\n",
    "    data_train, y_train = shuffle(data_train, y_train, random_state=rs)\n",
    "    \n",
    "    SS_data =StandardScaler()\n",
    "    #SS_y = StandardScaler()\n",
    "\n",
    "    data_train =  SS_data.fit_transform(data_train)\n",
    "    data_test = SS_data.transform(data_test)\n",
    "    data_pca, _ = func_PCA(pca_comp, data_train)\n",
    "    data_pca_test, _ = func_PCA(pca_comp, data_test)\n",
    "    clf = DT()\n",
    "    data_dt = clf.fit_transform(data_pca, y_train)\n",
    "    cv_scores = (np.mean(cross_val_score(clf, data_dt, y_train, cv=3)))\n",
    "    score_train = clf.score(data_pca, y_train)\n",
    "    score_test = clf.score(data_pca_test,y_test)\n",
    "    print(\"Training Size = %f(%f), Cross Validation Score = %f, Train Score = %f \\n Testing size=%d, Testing Score = %f\"%(trainsize,len(y_train),cv_scores,score_train,len(y_test), score_test))\n",
    "    return cv_scores, score_train, score_test, data_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size = 0.200000(97.000000), Cross Validation Score = 0.815109, Train Score = 1.000000 \n",
      " Testing size=389, Testing Score = 0.683805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size = 0.300000(145.000000), Cross Validation Score = 0.848024, Train Score = 1.000000 \n",
      " Testing size=341, Testing Score = 0.812317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size = 0.400000(194.000000), Cross Validation Score = 0.830074, Train Score = 1.000000 \n",
      " Testing size=292, Testing Score = 0.767123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size = 0.500000(243.000000), Cross Validation Score = 0.847517, Train Score = 1.000000 \n",
      " Testing size=243, Testing Score = 0.761317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size = 0.600000(291.000000), Cross Validation Score = 0.827967, Train Score = 1.000000 \n",
      " Testing size=195, Testing Score = 0.805128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size = 0.700000(340.000000), Cross Validation Score = 0.814832, Train Score = 1.000000 \n",
      " Testing size=146, Testing Score = 0.712329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size = 0.800000(388.000000), Cross Validation Score = 0.798966, Train Score = 1.000000 \n",
      " Testing size=98, Testing Score = 0.775510\n",
      "Training Size = 0.900000(437.000000), Cross Validation Score = 0.839763, Train Score = 1.000000 \n",
      " Testing size=49, Testing Score = 0.795918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Finding optimal training data size\n",
    "\n",
    "n  = np.arange(0.2,1,0.1)\n",
    "for i in n:\n",
    "    func_dectree(data, i, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FInding optimal number of PCA components\n",
    "n  = np.arange(20,42,5)\n",
    "for i in n:\n",
    "    func_dectree(data, 0.6,i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
